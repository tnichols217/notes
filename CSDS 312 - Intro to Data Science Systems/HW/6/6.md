# 6

## 1

Compare the performance between the OpenACC and CUDA codes using batch job submission (using SLURM job script after creating it) in reference to Prime Numbers code demonstrated in the class.

### a

OpenACC Code (primeNumbersAcc.c) at ~/csds312/openacc/

```bash
cd ~/csds312/openacc
module load NVHPC
nvc -Minfo=all -acc -gpu=cc75 primeNumbersAcc.c -o primeNumbers
tee job.slurm <<EOF
#!/bin/bash
#SBATCH -J prime_cuda
#SBATCH -A csds312
#SBATCH -p markov_gpu
#SBATCH --gres=gpu:1
#SBATCH -o prime_cuda_%j.out
#SBATCH -e prime_cuda_%j.err

time ~/csds312/openacc/primeNumbers
EOF
sbatch job.slurm
```

This gives me the result of

```text
real	0m1.910s
user	0m1.641s
sys		0m0.249s
```

### b

CUDA code (primeNumbers.cu) at ~/csds312/cuda

```bash
cd ~/csds312/cuda
module load CUDA
nvcc primeNumbers.cu -o primeNumbers
tee job.slurm <<EOF
#!/bin/bash
#SBATCH -J prime_cuda
#SBATCH -A csds312
#SBATCH -p markov_gpu
#SBATCH --gres=gpu:1
#SBATCH -o prime_cuda_%j.out
#SBATCH -e prime_cuda_%j.err

module load CUDA

time ~/csds312/cuda/primeNumbers
EOF
sbatch job.slurm
```

This gives me the result of

```text
real	0m0.815s
user	0m0.514s
sys		0m0.205s
```

This shows us that the CUDA native code is faster.
