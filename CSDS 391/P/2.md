# 1
## a

The update algorithm for k-means clustering derived from W5-Q1 was
$\frac{\sum\limits_{n=1}^Nr_{n,k}\vec x_n}{\sum\limits_{n=1}^Nr_{n,k}}=\vec\mu_k$

Which simply means update the means of each cluster to the mean of its components.

***Defined in*** *kmeans.py>kMeans>updateMeans*

## b

![[Pasted image 20231121000057.png]]
*Fig. 1*

Bottom-left: Objective function over iterations for 2 clusters
Top-left: Clusters and decision boundaries for 2 clusters
Bottom-right: Objective function over iterations for 3 clusters
Top-right: Clusters and decision boundaries for 3 clusters

***Objective function defined in*** *kmeans.py>kMeans>getObjective*

## c

![[Pasted image 20231121000437.png]]
*Fig. 2*
Clusters, cluster centers, decision boundaries at 0 steps

![[Pasted image 20231121000539.png]]
*Fig. 3*
Clusters, cluster centers, decision boundaries at early-intermediary optimization

![[Pasted image 20231121000623.png]]
*Fig. 4*
Clusters, cluster centers, decision boundaries at late-intermediary optimization

See *Fig. 1* for converged clusters

***Graphics generated in*** *\_\_init\_\_.py::31*

## d

I devised a method that utilizes voronoi to view the decision boundaries. I created two variants: one that utilizes all dimensions of the converged means and one that only calculates the voronoi on the graphed screen-space. I settled on the multidimentional solution as it felt more correct and representative of the data even though the visuals look less correct. Voronoi represents a space where cells are calculated by their nearest voronoi center, which in this case is are the centers of each cluster. For displaying it along the data i opted to calculate the 2D intersection over the relevant dimensions across the multi dimentional voronoi representation.

*See Fig. 1-4 for visuals*

***Defined in*** *solver.py*

# 2

## a

![[Pasted image 20231121001632.png]]

*Fig. 5*
Subset of the Iris dataset only containing "Versicolor" (red) and "Virginica" (green) with example linear classifier with displayed weights and biases with a sigmoid non-linearity.

## b

$o=f((w@i^T)^T+b)$

Where $w$ is the matrix of weights, $i$ is a matrix of input vectors, $b$ is the bias, $@$ is defined as matrix multiplication, $^T$ is defined as the transpose of a matrix, and $o$ is the output 