# Learning Probabilistic Models

> [!def]
> **Bayesian Learning**
> Calculating the probability of each hypothesis given the data, and making predictions based on the outcomes
> 
> ---
> 
> **Bayes Law for vectors**
> Across multiple hypotheses,
> $P(h_i|\vec d)=\alpha P(\vec d|h_i)P(h_i)$
> where $\alpha$ is a constant
> 
> $P(X|\vec d)=\sum\limits_i^IP(X|h_i)P(h_i|\vec d)$
> By the law of total probability
> 
> $P(\vec d|h_i)=\prod\$


